\section{\Tool{}-based applications}%
\label{sec:applications}

We demonstrate \tool{}'s practicality by building three applications on top of
it, each a research contribution in its own right.
%
First, we build an application that allows a service provider to disclose its
infrastructure configuration in a user-verifiable way, thus eliminating the
trust that users have to have in third-party infrastructure (\S~\ref{sec:vct}).
%
Second, we demonstrate 

the operation of a Tor bridge inside an enclave, which
mitigates several classes of attacks that the Tor network has struggled with in
the past (\S~\ref{sec:tor-bridge}).
%
Third, we show that \tool{} can handle computationally expensive workloads by
moving a Web browser into an enclave and letting users interact with it via a
remote desktop environment (\S~\ref{sec:browser}).

\subsection{Verifiable configuration transparency}%
\label{sec:vct}

Service providers typically outsource their infrastructure to third-party
providers like content delivery networks or cloud computing vendors.  The
specific configuration of these third-party providers often affects user
privacy.  For example, a service provider may configure a third-party reverse
proxy to strip client IP addresses before requests are forwarded to the servers
that are under the service provider's control.  How can the service provider
prove to its users that it configured the reverse proxy as promised?  We built
an enclave application that discloses the service provider's configuration in a
user-verifiable way, eliminating the trust that users have to place in the
configuration of third-party infrastructure.

The idea, illustrated in Figure~\ref{fig:vct}, consists of a lightweight
enclave application whose sole purpose is to answer client requests by querying
the API of the third-party infrastructure provider.  We built our
proof-of-concept implementation for Cloudflare but the code can easily be
adapted to support other providers.

To interact with Cloudflare's API endpoint, one needs a confidential bearer
token for authentication and a semi-confidential zone
ID~\cite{spectrum-config}.  Unlike the API endpoint URL, these two values
cannot be hard-coded in the (public) source code of the enclave application.
We therefore add a second Web server to the enclave application whose only
purpose is to receive as input the bearer token and the zone ID (cf.
\S~\ref{sec:secrets}).  We carefully constrained this Web server's HTTP
handlers, making it impossible to inject anything into the enclave \emph{but}
the bearer token and the zone ID.  We further configured the proxy to only
forward connections from the EC2 host to this Web server.  Internet-connected
adversaries cannot reach this Web server.  After the administrator launched the
enclave, she ingests the confidential values into the enclave by calling the
private HTTP endpoint from the EC2 host.  Users have no reason to be concerned
about this secret endpoint because the enclave application's source code
clearly shows that the secret values are only used as part of the API request
to Cloudflare.

\begin{figure}[t]
  \centering
  \input{sections/figures/vct}
  \caption{An overview of the enclave application that provides verfiable
  configuration transparency.  After launching the enclave, the operator
  configures the confidential bearer token and zone ID~(\ding{202}).  Clients
  can then request the service provider's Cloudflare
  configuration~(\ding{203}).  The application makes an HTTP request (containing
  the bearer token and zone ID) to Cloudflare's API~(\ding{204}).  Finally, the
  application asks its hypervisor for an attestation document~(\ding{205}) and
  embeds the attestation document in the response to the client, along with
  Cloudflare's response.}%
  \label{fig:vct}
\end{figure}

Clients communicate with this enclave application via a single endpoint, which
returns the JSON-encoded Cloudflare configuration.  When calling this endpoint,
users provide a nonce in their GET request to convince themselves of the
enclave's ``freshness'' (cf.~\ref{sec:attestation}).  In summary, clients make
the following request:


\begin{lstlisting}[numbers=none,basicstyle=\small\ttfamily]
GET /verify?nonce=3a26d...a937f HTTP/2
Host: enclave.example.com
\end{lstlisting}

And the server responds with:

\begin{lstlisting}[numbers=none,basicstyle=\small\ttfamily]
HTTP/2 200 OK
Date: Mon, 13 Mar 2023 18:34:29 GMT
Content-Type: application/json
X-Attestation-Document: hEShATgioFkRJalpbW9kdWx...

{
  "domain": "service.provider.com",
  "modified_on": "2021-09-08T18:04:10.711156Z",
  ...
}
\end{lstlisting}

Upon receiving the enclave's response, the client first verifies the
authenticity of the attestation document (cf. \S~\ref{sec:attestation}).  Once
convinced that the enclave's response is authentic, the client inspects the
body of the response---which comes directly from Cloudflare's API.  In
particular, the client consults Cloudflare's API documentation to verify that
the service provider configured Cloudflare correctly.  Finally, the user
verifies that the domain inside the enclave's response matches the domain that
the service provider makes available to its users.

\subsection{Tamper-resistant Tor bridge}
\label{sec:tor-bridge}

The Tor network's security rests on the assumption that certain relays in a
user's circuit do not collude.  This assumption does not always hold, as in the
2014 attack that sought to deanonymize onion service
users~\cite{Dingledine2015a}.  The attack consisted of several malicious relays
that injected a sequence of \texttt{RELAY} and \texttt{RELAY\_EARLY} cells to
encode a messages along the circuit~\cite[\S~5.6]{tor-spec}.  This was an active
attack and therefore required a non-standard implementation that deviates from
the Tor protocol.  If done well, such attacks can be difficult for clients to
recognize.

\Tool{} can help mitigate such attacks by running Tor infrastructure inside an
enclave.  By taking advantage of remote attestation, Tor clients can rest
assured that they are communicating with an authentic Tor implementation that
does not deviate from the Tor protocol.  We demonstrate that this is possible
by setting up a Tor bridge inside an enclave.\footnote{We chose to set up a Tor
bridge instead of a relay because bridges can be configured to remain private
and therefore cause no harm to the network in case our implementation had
bugs.}

\subsubsection{Proof-of-concept deployment}

Running the Tor executable inside an enclave is straightforward: the Dockerfile
and startup script are nearly identical to Listing~\ref{fig:example}.  Remote
attestation however is more complicated.  Ideally, Tor clients would attest the
authenticity of their Tor bridge as part of the Tor protocol itself but for the
sake of this prototype, we are content with handling remote attestation outside
the Tor protocol: Once the Tor bridge is done bootstrapping, it registers
its long-term identity key with \tool{}.  The enclave then exposes two TCP
ports: port 443 for \tool{} and port 9001 for Tor.  Before a Tor client
establishes a circuit over the bridge, it does remote attestation by fetching
an attestation document as explained in \S~\ref{sec:attestation}.  After
verifying the attestation document, the bridge establishes a Tor circuit
and---while establishing the circuit---verifies that the bridge's long-term
identity key is identical to the key in the attestation document.  If so, the
client can rest assured that it's talking to a publicly verifiable Tor bridge.

We implemented the aforementioned prototype and configured Tor Browser v12.0.1
to use our in-enclave bridge.  Using this setup, we were able to watch 2160p
YouTube videos free of buffering and other interruptions.
%
The above setup works well for an ad-hoc setup but is insufficient for
network-wide deployment of in-enclave relays and bridges.  In this case, relays
and bridges need a way to announce if they support relay attestation.  This is
the job of the Tor network's consensus, which is generated every hour by the
distributed directory authorities.  Changes to the network consensus are
complex and need to be addressed in the protocol specification and Tor's
reference implementation.

\subsubsection{Performance evaluation}

\phw{Provide some sort of performance evaluation to please the bean counters.}

\subsubsection{Comparison to SGX-Tor}

In their NSDI'17 paper, Kim et al. augmented the Tor code with SGX, thus giving
clients, relays, and directory authorities the ability to remotely verify each
other~\cite{Kim2017a}.  Our approach is similar but differs in the following
aspects:
%
Clients that seek to verify an SGX enclave's attestation document need to talk
to Intel's attestation service, which brings with it an array of privacy
problems~\cite[\S~1.2]{Chen2019a}.  With Nitro enclaves, clients can verify an
attestation document offline, provided that they have a copy of Amazon's root CA
public key.

% End-to-end correlation attacks.
Next, the authors envision the entire Tor network to take advantage of SGX,
which is not feasible in our approach: Nitro enclaves can only run in
Amazon-controlled AWS.  If all Tor relays ran inside AWS, Amazon would see both
traffic entering and exiting the network---ideal conditions for end-to-end
correlation attacks.  We therefore believe that only select Tor bridges benefit
from running in \tool{}, lest anonymity is jeopardized.

% Complexity of making it work.
As for practicality, Kim et al. had to go to great lengths to make Tor support
SGX~\cite[\S~5]{Kim2017a}.  Our proof-of-concept implementation took one
afternoon.  Finally, since Kim et al.'s paper was published, Intel announced the
discontinuation of SGX support for consumer-grade Core CPUs, which further
limits the number of SGX-capable Tor clients.

\phw{Elaborate on side channels that the EC2 host can exploit.}

\if 0
\subsection{IP address tokenization}
\label{sec:tokenization}

Service providers often have an incentive to record and analyze client IP
addresses to prevent fraud.  IP addresses can reveal an array of sensitive
information to the service provider, like the city that the user is located in.
Users therefore prefer that the service provider does not see their IP address.
We built an IP address tokenization system on top of \tool{} that provides
user-verifiable guarantees that the service provider anonymized the client's IP
address \emph{without seeing it in plain text}.  The service provider can then
run its anti-fraud logic over anonymized IP addresses without suffering a
significant loss in utility.

\begin{figure}[t]
\centering
\input{sections/figures/pseudonymizer-design}
\caption{Clients communicate with a service that's available behind a
  third-party TCP proxy whose purpose is (among other things) to drop client IP
  addresses, so the service never sees them.  The proxy is configured to mirror
  incoming client requests \emph{with} IP address to the enclave, where
  addresses are pseudonymized and finally forwarded to a back end for analysis.}
\label{fig:address-anonymizer}
\end{figure}

Figure~\ref{fig:address-anonymizer} illustrates our system's architecture.
Clients talk to a service that is fronted by a third-party reverse proxy.  The
reverse proxy is configured to strip client IP addresses before forwarding
requests.  The reverse proxy is also configured to duplicate incoming requests
to the enclave application.
% FIXME


Our first application is the system that originally motivated us to build the
enclave framework. Consider a service provider that offers various services to
its users.  The service provider seeks to know as little as possible about its
users, which means that it doesn't capture and store any of its users' IP
addresses.  IP addresses are however an important signal in the service
provider's fight against a subset of its users that commit fraud.  This
constitutes a conundrum: Should the service provider collect all its users' IP
addresses to strengthen its anti-fraud efforts?  Or continue to discard the
addresses, and tolerate the fraud?

This section presents an application that strikes a balance between these two
extremes; an IP address pseudonymization system that can verifiably pseudonymize
IP addresses.  The service provider can then run its anti-fraud logic over
pseudonymized IP addresses rather than real ones.  While some information is
lost in the process, we argue that what's most important---the relationship
between IP addresses---can be preserved thanks to our use of the Crypto-PAn
scheme that Xu et al. presented in their 2001 paper~\cite{Xu01a}.  Crypto-PAn
encrypts both IPv4 and IPv6 addresses by implementing a 1:1 mapping $f$ that is
keyed by $k$ from an IP address to its pseudonymized equivalent while
\emph{preserving the address's prefix}, i.e., two IP addresses that share an
$n$-bit prefix also share an $n$-bit prefix after pseudonymization as
illustrated by the following example:

\begin{align}
f(k, \textrm{``\underline{10.0.0.}1''})\phantom{23} = \textrm{``\underline{242.32.192.}193''} \\
f(k, \textrm{``\underline{10.0.0.}123''}) = \textrm{``\underline{242.32.192.}154''}
\end{align}

Figure~\ref{fig:address-anonymizer} illustrates the system design.  Clients
periodically communicate with a service behind a reverse TLS proxy whose
job---among other things---is to hide client IP addresses from the service.  The
proxy is configured to mirror incoming client requests to the enclave, but with
client IP addresses intact, in the form of a custom HTTP header like
\texttt{X-Client-Addr: 1.2.3.4}.  The service is interactive, and responds to
the client, but the enclave is passive, and simply consumes the requests.
Recall that the (untrusted) EC2 host that hosts the enclave is unable to see
the client's IP address because the TLS proxy establishes a TLS session that's
terminated \emph{inside} the enclave.  The pseudonymizer takes as input client
requests, extracts the IP address that the proxy inserted from the HTTP header,
pseudonymizes them, and forwards pseudonymized addresses in batches to the
configured back end.  Components in dark gray are under the service provider's
control.


One problem however remains: how do clients know that the TLS proxy is in fact
configured to discard client IP addresses before forwarding requests to the
service?  Unfortunately, cloud providers don't offer satisfying solutions for
this problem but some cloud providers allow for the creation of roles whose
permissions are configurable.  The service provider can create a read-only role
in the TLS proxy's configuration interface and publish the credentials for this
role.  Doubtful users can then log in to this role and verify that the TLS proxy
is configured to discard IP addresses when forwarding requests to the service.
As long as the TLS proxy operator is a neutral third party with no incentive to
lie, which is typically the case, both the client and service provider can trust
it.  We acknowledge that this is not an elegant solution but a mere hack, to
work around the shortcoming of Nitro enclaves not having a networking interface.
If enclaves had a networking interface that could not be monitored by the
untrusted EC2 host, clients could directly talk to the enclave, obviating the
need for a TLS proxy that hides client IP addresses from the EC2 host.

\paragraph{Side channels}
The untrusted EC2 host never sees client IP address in plaintext
but it can exploit timing and volume side channels to infer information about
the encrypted requests that the TLS proxy forwards to the enclave.  We close
this side channel by adding code to the enclave application which queues
pseudonymized IP addresses until two conditions are true: (\emph{i}) we have at
least $n$ pseudonymized addresses, and (\emph{ii}) at least $t$ minutes have
passed.

\paragraph{Key rotation} A single pseudonymous IP address without context cannot
be reversed and reveals nothing about its corresponding plaintext IP address but
that changes if the service provider expects the client to repeatedly report its
IP address to the enclave.  For example, a sequence of pseudonymized IP
addresses can reveal either that (\emph{i}) the client has not changed its IP
address, or (\emph{ii}) the client changed its IP address but is likely to use
the same ISP (e.g., if the /24 prefix remains the same), or (\emph{iii}) the
client changed IP addresses \emph{and} ISPs (e.g., if the prefixes of the
pseudonymous IP addresses share less than, say, eight bits).  While this is
useful information for anti-fraud operations,\footnote{For example, a service
provider would deem a client that constantly changed ISPs suspicious; it is
likely to use proxies to connect to the service provider's infrastructure.} it
also reveals information about a given client's location, and service providers
may want to err on the side of privacy instead.  We therefore added a mechanism
for periodic key rotation, so a given client's pseudonymized IP addresses are
only meaningful within a given rotation period.  According to the results of
Padmanabhan et al., we believe that a key rotation period of three weeks strikes
a useful balance between privacy for the client and usefulness for the service
provider~\cite[\S~3.2]{Padmanabhan20a}: several ISPs re-assign many of their
users' IP addresses in less than---or up to---two weeks.

In the final step, the enclave submits the client's pseudonymized IP address and
a hash of the key to the service provider's back end, where anti-fraud logic is
implemented.  The implementation details of both the back end and its anti-fraud
logic are beyond the scope of this paper.

\paragraph{Implementation}
Our pseudonymization service counts approximately 1,100 lines of code, including
comments and tests.  It is important to keep the source code small for both
security and transparency: a large code base is more likely to have
security-critical bugs and is also more difficult for users to audit.

\paragraph{Alternative pseudonymization}
In addition to Crypto-PAn, we implemented a second pseudonymization method that
is based on HMAC-SHA-256.  Like Crypto-PAn, the HMAC is keyed by a 160-bit
secret that the enclave generates when first bootstrapping.  Unlike Crypto-PAn
however, the HMAC-based method does not preserve the prefixes of IP addresses:
two IP addresses that differ in only a single bit will result in entirely
different hashes.  On the privacy/utility spectrum, the HMAC-based method
therefore leans more toward privacy.
\fi

\subsection{In-enclave Web browser}%
\label{sec:browser}

advantages:
+ enabling thin clients
+ isolate browser from the client's system

disadvantages:
- interaction with file system not straightforward

comparison to other approaches
+ cloudflare's thing~\cite{cf-browser-isolation}
+ webenclave~\cite{Wang2021a}
