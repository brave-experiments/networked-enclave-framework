\section{Applications}
\label{sec:applications}

We demonstrate the practicality of our system by building on it to solve two
real-world problems.  First, in a novel system that pseudonymizes client IP
addresses for anti-fraud (\S~\ref{sec:pseudonymization}); second, to implement
the shuffler service as proposed in the PROCHLO paper~\cite{Bittau2017a}
(\S~\ref{sec:shuffler}).  In both cases, we had to overcome minor obstacles but
found that our framework greatly facilitated the deployment of enclave code.

While our framework is written in Go, developers can build enclave applications
in languages other than Go, by taking advantage of a foreign function interface
(FFI) that allows Go code to invoke functions in other languages.  We
successfully moved a Rust code base into a Nitro enclave by implementing a
lightweight, Go-based wrapper (in less than 200 lines of code, excluding our
framework's code) that interacts with the Rust code via an FFI.\footnote{The
code is publicly available but we don't link to it yet to preserve our
anonymity.} Importantly, the compilation process is still reproducible as long
as the Rust code's dependencies are pinned via a Cargo.lock file.

\subsection{IP Address Pseudonymizer}
\label{sec:pseudonymization}

Our first application is the system that originally motivated us to build the
enclave framework. Consider a service provider that offers various services to
its users.  The service provider seeks to know as little as possible about its
users, which means that it doesn't capture and store any of its users' IP
addresses.  IP addresses are however an important signal in the service
provider's fight against a subset of its users that commit fraud.  This
constitutes a conundrum: Should the service provider collect all its users' IP
addresses to strengthen its anti-fraud efforts?  Or continue to discard the
addresses, and tolerate the fraud?

This section presents an application that strikes a balance between these two
extremes; an IP address pseudonymization system that can verifiably---thanks to
enclaves---pseudonymize IP addresses.  The service provider can then run its
anti-fraud logic over pseudonymized IP addresses rather than real ones.  While
some information is lost in the process, we argue that what's most
important---the relationship between IP addresses---can be preserved thanks to
our use of the Crypto-PAn scheme that Xu et al. presented in their 2001
paper~\cite{Xu01a}.  Crypto-PAn encrypts both IPv4 and IPv6 addresses by
implementing a 1:1 mapping $f$ that is keyed by $k$ from an IP address to its
pseudonymized equivalent while \emph{preserving the address's prefix}, i.e., two
IP addresses that share an $n$-bit prefix also share an $n$-bit prefix after
pseudonymization as illustrated by the following example:

\begin{align}
f(k, \textrm{``\underline{10.0.0.}1''})\phantom{23} = \textrm{``\underline{242.32.192.}193''} \\
f(k, \textrm{``\underline{10.0.0.}123''}) = \textrm{``\underline{242.32.192.}154''}
\end{align}

Figure~\ref{fig:address-anonymizer} illustrates the system design.  Clients
periodically communicate with a service behind a reverse TLS proxy whose
job---among other things---is to hide client IP addresses from the service.  The
proxy is configured to mirror incoming client request to the enclave, but with
client IP addresses intact, in the form of a custom HTTP header like
\texttt{X-Client-Addr: 1.2.3.4}.  The service is interactive, and responds to
the client, but the enclave is passive, and simply consumes the requests.
Recall that the (untrustworthy) EC2 image that hosts the enclave is unable to
see the client's IP address because the TLS proxy establishes a TLS session
that's terminated \emph{inside} the enclave.  The pseudonymizer takes as input
client requests, extracts the IP address that the proxy inserted from the HTTP
header, pseudonymizes them, and forwards pseudonymized addresses in batches to
the configured back end.  Components in dark gray are under the service
provider's control.

\begin{figure}[t]
\centering
\input{sections/figures/pseudonymizer-design}
\caption{Clients communicate with a service that's available behind a
  third-party TCP proxy whose purpose is (among other things) to drop client IP
  addresses, so the service never sees them.  The proxy is configured to mirror
  incoming client requests \emph{with} IP address to the enclave, where
  addresses are pseudonymized and finally forwarded to a back end for analysis.}
\label{fig:address-anonymizer}
\end{figure}

One problem however remains: how do clients know that the TLS proxy is in fact
configured to discard client IP addresses before forwarding requests to the
service?  Unfortunately, cloud providers don't offer satisfying solutions for
this problem but some cloud providers allow for the creation of roles.  The
service provider could create a read-only role in the configuration interface
for the TLS proxy and publish the credentials for this role.  Doubtful users can
then log in to this role and verify that the TLS proxy is configured to discard
IP addresses when forwarding requests to the service.  As long as the TLS proxy
operator is a neutral third party with no incentive to lie, both the client and
service provider can trust it.

\paragraph{Side channels}
The untrustworthy parent EC2 instance never sees client IP address in plain text
but it can exploit timing and volume side channels to infer information about
the encrypted requests that the TLS proxy forwards to the enclave.  We close
this side channel by queuing pseudonymized IP addresses for a configurable time
period before forwarding them to the back end.

\paragraph{Key rotation}
A single pseudonymous IP address without context cannot be reversed and reveals
nothing about its corresponding plain-text IP address but that changes if the
service provider expects the client to repeatedly report its IP address to the
enclave.  For example, a sequence of pseudonymized IP addresses can reveal
either that (\emph{i}) the client has not changed its IP address, or (\emph{ii})
the client changed its IP address but is likely to use the same ISP (e.g., if
the /24 prefix remains the same), or (\emph{iii}) the client changed IP
addresses \emph{and} ISPs (e.g., if the prefixes of the pseudonymous IP
addresses share less than, say, eight bits).  While this is useful information
for anti-fraud operations, it also reveals a lot about a given client's
location, and service providers may want to err more on the side of client
privacy.  We therefore added a mechanism for periodic key rotation, so a given
client's pseudonymized IP addresses are only meaningful within a given rotation
period.  According to the results of Padmanabhan et al., we believe that a key
rotation period of three weeks strikes a useful balance between privacy for the
client and usefulness for the service provider~\cite[\S~3.2]{Padmanabhan20a}:
several ISPs re-assign many of their users' IP addresses in less than---or up
to---two weeks.

In the final step, the enclave submits the client's pseudonymized IP address and
a hash of the key to the service provider's back end, where anti-fraud logic is
implemented.  The implementation details of both the back end and its anti-fraud
logic are beyond the scope of this paper.

\paragraph{Implementation}
Our pseudonymization service counts approximately 1,000 lines of code, including
comments and tests.  It is important to keep the source code small for both
security and transparency: a large code base is more likely to have
security-critical bugs and is also more difficult to audit for users.

\subsection{$k$-anonymity Enforcer}
\label{sec:shuffler}

Bittau et al.'s SOSP'17 paper~\cite{Bittau2017a} proposes a private analytics
system that helps service providers gain insight into their clients' usage
patterns.  Their system---called PROCHLO---consists of three components:
(\emph{i}) software running on the client, which can (but doesn't have to) add
local differential privacy to client measurements.  These measurements are then
sent to (\emph{ii}) a shuffler, which enforces a configurable $k$-anonymity
threshold on incoming measurements.  The shuffler then sends all remaining
measurements to (\emph{iii}) an analytics system that the service provider uses
to explore users' anonymized data.  The PROCHLO paper envisions the shuffler to
run in a secure enclave; otherwise users would have no reason to trust that the
shuffler is in fact enforcing $k$-anonymity thresholds.  To that end, the
authors designed the shuffler to run inside an SGX enclave, which was
challenging considering the memory constraints that SGX imposes.

As part of an unrelated research project, we were experimenting with private
telemetry, and we therefore used our framework to re-implemented the shuffler in
approximately 1,000 lines of code.\footnote{The code is freely available but we
omit a link to it to preserve our anonymity.}  Our implementation is a
near-complete clone of the shuffler as it was proposed in the PROCHLO paper but
for simplicity, we did not implement nested encryption~\cite[\S~3]{Bittau2017a}.
Figure~\ref{fig:shuffler} shows that our shuffler takes as input confidential
client measurements and enforces a configurable $k$-anonymity threshold on those
measurements.  Every $t$ seconds, the shuffler discards messages that don't meet
the threshold and forwards the remaining messages to its back end.\footnote{The
variable $t$ depends on the rate of incoming measurements.  Reasonable values
can range from hours (if the shuffler constantly sees a high rate of incoming
measurements) to days.} Before clients agree to sending their sensitive
measurements to the shuffler, they audit its source code and perform remote
attestation, to convince themselves that their measurements are processed by an
authentic enclave.

\begin{figure}[t]
\centering
\input{sections/figures/shuffler-design}
\caption{A conceptual overview of our shuffler implementation.  Clients send
  measurements to the shuffler, which enforces a $k$-anonymity threshold---in
  this case for $k$=2. Only one of the two measurement types passes the
  threshold and is forwarded to the back end.}
\label{fig:shuffler}
\end{figure}

Compared to Bittau et al.'s original, SGX-based design, our Nitro-based
implementation has two key advantages: (\emph{i}) Nitro's underlying hardware
isolation makes our implementation more robust to side channel attacks and
(\emph{ii}) Nitro doesn't suffer from the same resource constraints as SGX,
which renders our implementation simpler and less error-prone.
