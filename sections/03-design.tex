\section{Framework Design}
\label{sec:design}

We start by laying out the involved parties and their respective trust
assumptions (\S~\ref{sec:trust-assumptions}), followed by an overview of our
system (\S~\ref{sec:overview}).  We then discuss the two major aspects of our
framework: the build system (\S~\ref{sec:build-system}) and the framework
(\S~\ref{sec:framework}).

\subsection{Trust Assumptions}
\label{sec:trust-assumptions}

Our setting has three participants that have the following trust assumptions:

\begin{enumerate}
    \item The \emph{service provider} wants to process sensitive client
      information.

    \item The \emph{client} is a user of the service provider.  It does not
      trust the service provider with its sensitive information and seeks
      verifiable guarantees that the service provider will never see the
      client's sensitive information in plaintext.

    \item The \emph{enclave provider} makes available enclaves to the service
      provider.  Both the client and the service provider trust that the
      enclave provider's enclaves have the security attributes of integrity,
      confidentiality, and verifiability.  The client trusts that the enclave
      provider and service provider don't collude.
\end{enumerate}

\subsection{Overview}
\label{sec:overview}

We begin with a short, informal overview of our system to provide intuition.
The subsequent sections are going to elaborate on this high-level picture.  

\begin{enumerate}
    \item The service provider implements a new service with the intention of
      running it in an enclave.  Once the implementation is finished, the
      service provider publishes the source code for the clients to audit, and
      runs the code in an enclave.  After booting, the enclave obtains a
      CA-signed TLS certificate.

    \item Users audit the source code.  Once a user has convinced herself that
      the code is free of bugs, she compiles the code using the framework's
      deterministic build system, resulting in an image checksum.

    \item The client establishes an end-to-end encrypted network connection to
      the enclave.  Right \emph{after} establishing the connection but
      \emph{before} revealing any sensitive information, the client provides a
      nonce and asks the enclave for an attestation document.

    \item The enclave receives the nonce and asks its hypervisor to generate an
      attestation document that should contain the client-provided nonce
      \emph{and} the fingerprint of the enclave's CA-signed certificate.  The
      resulting attestation document is returned to the client.

    \item The client performs various checks (see \S~\ref{sec:attestation} for
      details) and trusts the enclave if all checks pass.  The client is then
      convinced that it's communicating with the code that the user audited in
      the previous steps, and is willing to reveal her sensitive information to
      the enclave.
\end{enumerate}

% As illustrated in Figure~\ref{fig:overview}, clients submit their IP address
% to the enclave, which is run by the enclave provider but its code comes from
% the service provider.  It's not possible to talk to the enclave directly
% because all communication happens via the (untrustworthy) parent EC2
% instance, which is why we introduce a TCP proxy (run by the infrastructure
% provider), which prevents the EC2 instance from seeing the client's IP
% address.  The client establishes a TLS session that is terminated inside the
% enclave and can therefore be sure that its IP address is sent to the enclave,
% and the enclave only.

% After the enclave received the client's address, it responds with a nonce.
% The enclave does not know if the client reported its real address or a fake
% address, so it must actively verify the address, but it cannot connect to the
% client directly because that would allow the EC2 instance to see the client's
% IP address.  To solve this problem, we make the enclave talk to the client
% via a VPN node.  Upon connection establishment, the client must send the
% nonce it received from the enclave in the previous step.  Once the enclave
% recognizes the nonce, it rests assured that the client really does control
% the IP address it submitted earlier.

% In the final step, the enclave anonymizes the client's IP address and
% forwards it to its back end.

\subsection{The Reproducible Build System}
\label{sec:build-system}

% Why it's not a big deal that only some users can audit our code.
Only a small subset of the users will be skilled enough programmers to audit
the enclave's code for bugs.  We expect non-technical users to trust that other
users---or perhaps professional code audit companies---have studied the code
and pointed out potential bugs.  Once a user has convinced herself of the code's
correctness, she compiles the code to arrive at an image ID.  Crucially, we
need a \emph{deterministic mapping} between the code and its corresponding
image ID because the service provider and clients must agree on the image ID
that's running in the enclave.

The popular Docker tool does not offer a deterministic mapping because, among other things,
Docker records timestamps in its build process, causing subsequent builds of
identical code to result in different image IDs.\footnote{In essence, an image
is simply a file system.  If an image is reproducible, separate build processes
arrive at the exact same file system.}  To obtain reproducible builds, we use
the tool kaniko~\cite{kaniko}.  Kaniko's main purpose is to build container
images from a Dockerfile while itself in a container, but we use kaniko because
it can do so reproducibly.  As long as the client and service provider use the
same enclave source code, Go version, and kaniko version, they can build
identical images---even when compiling the code on different platforms, like
Mac OS and Linux.  Equipped with a locally-compiled container image ID, the
client is now ready to interact with the enclave.

\subsection{Framework Features}
\label{sec:framework}

Having established how one can build applications reproducibly, we now turn to
the specific features of our framework.  The following sections discuss how the
framework communicates with the outside world (\S~\ref{sec:networking});
how it seeds its empty entropy pool (\S~\ref{sec:entropy});
how it obtains a CA-signed certificate (\S~\ref{sec:cert});
how we facilitate remote attestation (\S~\ref{sec:attestation});
how enclaves can share their key material to allow for horizontal scaling (\S~\ref{sec:sync});
how to thwart side-channel attacks (\S~\ref{sec:side-channels}), and
how to ingest secrets (\S~\ref{sec:secrets}.

\subsubsection{Enabling Networking}
\label{sec:networking}

Recall from Section~\ref{sec:nitro} that Nitro enclaves have no dedicated
network interface and are only able to communicate with their respective EC2
host.  Our framework therefore needs to provide code that runs on the parent
EC2 host and forwards packets between clients and the enclave.
Figure~\ref{fig:networking} illustrates our networking architecture.

When the enclave first starts, it fetches a CA-signed certificate from Let's
Encrypt (see Section~\ref{sec:cert} for more details).  To do so, it first
connects to Let's Encrypt's infrastructure via a SOCKS proxy.  Let's Encrypt
does not publish its endpoints' IP addresses, which is why we cannot use
point-to-point connections and have to rely on the flexibility of a SOCKS
proxy.\footnote{We implemented both the SOCKS proxy and the TCP proxy, and make
both available under a free license.}

Clients establish end-to-end encrypted TLS sessions with the enclave via a TCP
proxy on the EC2 machine that translates between AF\_INET and AF\_VSOCK.  Note
that the EC2 machine only sees encrypted data. Clients should further only
connect to the EC2 machine via a third-party reverse proxy, which also hides
the client's network identity from the EC2 machine.

In case of a compromise, we don't want the application to be able to leak data
to an attacker-controlled endpoint via the SOCKS proxy, which is why we use an
allow list on the SOCKS proxy.  In a typical application, the allow list
consists of two endpoints:

\begin{enumerate}
    \item The domain name acme-v02.api.letsencrypt.org to interact with Let's
      Encrypt.
    \item The IP address of whatever back end machine the enclave needs to talk
      to.
\end{enumerate}


\newcommand{\addr}[1]{{\footnotesize \color{gray}#1 }}

\begin{figure}[t]
\centering
\input{sections/figures/network-architecture}
\caption{Upon bootstrapping, the application first asks the hypervisor for
  randomness to seed its entropy pool (\ding{202}), followed by initiating an
  ACME session to obtain a Let's Encrypt-signed certificate (\ding{203}), after
  which Let's Encrypt probes the enclave and issues the certificate
  (\ding{204}).  Afterwards, clients can establish HTTPS connections with the
  enclave (\ding{205}) and the enclave can forward data to its back end
  (\ding{206}).  All of the application's ingress and egress  traffic is routed
  over a TCP proxy that translates between AF\_INET and AF\_VSOCK.  Egress
  traffic is reaches the Internet via a SOCKS proxy.}
\label{fig:networking}
\end{figure}

\subsubsection{Seeding the Entropy Pool}
\label{sec:entropy}

Like virtual machines, a Nitro secure enclave is an entropy-starved, sterile
environment that lacks access to periphery devices that help the kernel seed its
entropy pool.  To work around that, the Nitro hypervisor can provide randomness
that the enclave can use to seed its entropy pool.  Our framework automatically
takes advantage of that when it first starts, so application developers should
never encounter function calls that block because of a lack of randomness.

\subsubsection{End-to-end Secure Channel}
\label{sec:cert}

Having established how the enclave can send and receive network packets, we now
turn our attention to secure channels.  More specifically: how can a host on
the Internet be sure that it's talking to audited enclave application code,
without taking advantage of an existing trust relationship?

We implement a secure channel based on HTTPS.  Once the enclave has initialized its
entropy pool, it obtains an HTTPS certificate that allows clients to establish
end-to-end encrypted session with the enclave.  Crucially, the HTTPS
certificate \emph{lives and dies} inside the enclave and its private key cannot
be extracted (or injected) by the service provider.  Our framework allows for
the creation of a self-signed certificate or a CA-signed certificate.  If a
self-signed certificate is desired, the framework creates and signs a
certificate for a given FQDN.  To get a CA-signed certificate, the framework
uses Let's Encrypt's ACME protocol because it allows for the generation of a
certificate with no human interaction.  In that case, the enclave initiates an
HTTP-01 challenge connection with Let's Encrypt's infrastructure via our SOCKS
proxy (cf. Figure~\ref{fig:networking}), and subsequently expects an incoming
connection from Let's Encrypt to port 80, which the hosting EC2 image forwards
to the enclave.  Note that the hosting EC2 machine could also obtain a valid
CA-signed certificate for the same FQDN because the enclave and the EC2 image
share a single IP address.  However, this is of little use to the EC2 machine
as we will discuss in the next section.

The application can register arbitrary HTTP handlers that are accessible to the
outside world.

\phw{Explain why we're not using AWS ACM.}

\subsubsection{Remote Attestation}
\label{sec:attestation}

By default, Nitro enclaves only allow for local attestation.  We now discuss how
we allow clients to remotely attest an enclave.  After the client establishes an
HTTPS connection with the enclave, it needs to know that (\emph{i}) the TLS
connection it just established is terminated inside the enclave (instead of by
the hosting EC2 machine) and (\emph{ii}) the enclave is running the code that the user
audited in the previous step.  To that end, the client requests the enclave's
\emph{attestation document}---a hypervisor-signed document that attests to the
container image ID that the enclave is running.  To request an attestation
document, the client provides a \emph{nonce}---a 20-byte random value---whose
purpose is to prevent the service provider from replaying attestation documents.
Phrased differently, the client provides a nonce to convince itself that it's
talking to a live enclave.  In particular, clients make the following HTTP
request to request an attestation document:

\begin{lstlisting}[numbers=none]
GET /attestation?nonce=8083...23b7 HTTP/1.1
\end{lstlisting}

\phw{Elaborate on how the attestation document is generated, and what it
contains.}

The enclave receives the request and the provided nonce through the TCP proxy, asks the hypervisor to
include the nonce \emph{and} the fingerprint of the enclave's X.509 certificate
in the attestation document, and sends the resulting attestation document to
the client.  By asking the hypervisor to include the certificate fingerprint in
the attestation document, we effectively bind a TLS session to an enclave.  The
client then verifies the following in order:

\begin{enumerate}
    \item The attestation document is signed by the AWS PKI whose public key is
      known to all parties.
    \item The challenge nonce is part of the attestation document.
    \item The fingerprint of the enclave's X.509 certificate from the TLS session is part of the
      attestation document.
    \item The enclave's image ID is identical to the image ID that the client
      compiled locally.
\end{enumerate}

If all four conditions hold, the client is convinced that it's talking to an
enclave that runs the code that the client audited in the previous step, and
that the TLS connection is terminated in the enclave.  Note that the hosting EC2
machine is able to intercept HTTPS connections with its own, CA-signed
certificate but clients will only trust the EC2 machine if (and only if) it can
present an attestation document that is valid for the enclave image, which it
can't because it is unable to spoof the AWS PKI signature that protects the
attestation document.  The only way for the EC2 machine to obtain such an
attestation document is to spawn an enclave that runs the exact code that the
client is expecting---and it already is doing exactly that.  Now that the client
has established a trust relationship with the enclave, it's ready to send
sensitive information to the enclave.

While attestation documents can be generated quickly and in rapid
succession---we present performance measurements in
Section~\ref{sec:attestation-performance}---they do require an extra round trip
between the client and the enclave before the client is willing to reveal
sensitive information: the client first provides a nonce to the enclave, the
enclave responds with an attestation document, and only after the client verified
the document is it willing to reveal its sensitive information.  To eliminate
that round trip, clients should use TLS session resumption once they have
verified the enclave's attestation document.  The service provider is unable to
tamper with the enclave's key material, so it's safe to re-use a
once-established TLS session and forgo the unnecessary round trip.

\paragraph{Client-side Verification}

Even for developers, remote attestation is a complex process that is difficult
to understand and work with.  To make matters more complex, in our setting end
users are expected to conduct remote attestation themselves.  We therefore made
a careful effort to abstract away technical details.  A user wishing to remotely
verify an enclave essentially asks herself ``Does the enclave that's exposed at
a given URL run the source code that I just audited?''  We built a tool set that
reduces the process to the running of a Makefile,\footnote{The source code is
publicly available but we redacted the URL to remain anonymous.} e.g.:

\begin{lstlisting}[numbers=none]
$ make verify CODE="/path/to/enclave/code/" \
              ENCLAVE="https://example.com/attest"
\end{lstlisting}

The first environment variable, \texttt{CODE}, points to the directory
containing the source code that the enclave is supposedly running, and the user
audited.  The second variable, \texttt{ENCLAVE}, points to the URL endpoint of
the enclave that the user's client is connecting to.  When the user runs this
command, the Makefile deterministically compiles the given source code to
obtain its image ID, asks the enclave for an attestation document, verifies the
document, and ensures that the attestation document is for the image ID that
was compiled in the first step.  If all checks pass, the tool informs the user
accordingly.

\subsubsection{Sharing Key Material}
\label{sec:sync}

Recall that enclaves are essentially sealed at runtime, preventing
anyone (including both Amazon and the service provider) from extracting key material that was generated
inside the enclave.  While this is a desirable property, it complicates
horizontal scaling.  If a single enclave is unable to handle the service
provider's traffic load, one must scale horizontally, by starting new enclaves.
In some applications, it is unacceptable for each enclave to use distinct key
material.  Instead, enclaves must synchronize their key material, so they
appear to the outside world like a single machine.

While it is possible to build key synchronization using tools like the AWS key
management service (KMS),\footnote{One could encrypt the keys using a KMS
policy that dictates that only enclaves are allowed to decrypt it, and store
the encrypted key in a location that all enclaves can access, e.g., an S3
bucket.} we refrain from using KMS because there is no straightforward way for
users to verify that the service provider is using KMS as promised.  We
therefore devise a new protocol that enables key synchronization without having
to rely on external services.

We solve this problem in two steps: \emph{discovery} and
\emph{synchronization}.  First, enclaves must be able to discover each other,
i.e., learn each other's IP addresses.  Then, enclaves can establish
connections to each other and initiate key synchronization.  Our protocol
dictates that when a new enclave bootstraps, it first tries to discover
already-existing enclaves.  If there are none, the enclave knows that it is the
``origin'' enclave; it generates new key material and is prepared to share it
with future enclaves.  If however it discovers other enclaves, the new enclave
establishes a connection to another randomly-chosen enclave and initiates key
synchronization.  Crucially, key material is only shared after \emph{mutual
attestation}, i.e., the original and subsequent enclaves attest each other, and
only exchange key material if remote attestation succeeds.  Key synchronization
happens in three steps, as illustrated in Figure~\ref{fig:key-synchronization}.

\begin{figure}[t]
  \centering
  \input{sections/figures/key-synchronization}
  \caption{When a new enclave bootstraps, it discovers existing enclaves by
    obtaining the DNS SRV record for its own, hard-coded FQDN.  The enclave then
    initiates key synchronization by first requesting a nonce.  Then, the new
    enclave requests the origin enclave's key material by submitting its own
    attestation document, followed by receiving the origin enclave's attestation
    document, which contains encrypted key material.}
  \label{fig:key-synchronization}
\end{figure}

\begin{enumerate}

  \item Once a new enclave is spun up, it queries the DNS SRV record of the FQDN
    that is hard-coded in the enclave, e.g., example.com.  The DNS resolver will
    return the record, containing a list of enclaves that are already running.
    The new enclave picks a random enclave from the list and initiates key
    synchronization.

  \item The new enclave asks the existing enclave for a random nonce,
    $\textrm{nonce}_o$.  The new enclave caches $\textrm{nonce}_o$ for one
    minute.

  \item The new enclave now requests the key material from the existing enclave.
    As part of the request, it provides its attestation document that contains
    $\textrm{nonce}_o$ (to prove freshness to the existing enclave);
    $\textrm{nonce}_n$ (the existing enclave is expected to add the nonce to its
    attestation document); and $K_n$ (a public key to which the key material
    should be encrypted).  Upon receipt of the new enclave's attestation
    document, the existing enclave verifies the attestation document's signature
    and ensures that the new enclave is running the same code, i.e., the PCR
    value that uniquely identifies the enclave image is identical.  Once the new
    enclave is convinced that it is dealing with a genuine new enclave, it
    creates an attestation document by including $\textrm{nonce}_n$ (to prove
    freshness to the new enclave) and $\textsf{Enc}(K_n, s)$---the key material
    $s$ is encrypted using the public key that the new enclave provided in the
    request.  Finally, the new enclave verifies the attestation document,
    decrypts the key material, and uses it to finish bootstrapping.

\end{enumerate}

% Security considerations.
Needless to say, the security of key synchronization is paramount.  The first
layer of defense is the fact that enclaves communicate with each other over a
virtual network that is part of the private Kubernetes cluster that the enclaves
run in.  Arbitrary hosts on the Internet are therefore unable to contact an
enclave and request its key material.  The second layer of defense is the fact
that an enclave first has to provide a valid attestation document before the
origin enclave reveals its key material.  As long as the origin enclave knows
that an identical and authentic copy of itself is asking for key material, it
will readily provide it.

\subsubsection{Side-channel Attacks}
\label{sec:side-channels}

The enclave's parent EC2 image cannot see \emph{what} clients submit but it can
see \emph{how much} clients submit and \emph{how long} it takes the enclave to
process data.  The EC2 image can exploit these side channels to learn more
about the client's confidential information and computation.  While such side
channels must be avoided, our framework is not the place to do so.  Instead, it
is the application developer's responsibility to identify and address side
channels.  Section~\ref{sec:applications} introduces two applications and
discusses side channel attacks in their respective setting.

Similarly, programming bugs in the enclave application are also out of scope for
this work.  Memory corruption attacks may be more difficult to mount against
enclave applications\footnote{The untrustworthy operating system (that may be
under the attacker's control) is prohibited by hardware to read the enclave
application's memory or registers in clear text, which forces the attacker to
operate blindly.} but Lee et al. showed that it's possible, by adapting a
return-oriented programming attack against SGX~\cite{Lee2017a}.

\subsubsection{Ingesting secrets}
\label{sec:secrets}

A key design requirement of our framework is that users can audit and verify the
code that is running inside an enclave, which means that the service provider is
unable to hide any software configuration from the user.  Service providers can
work around that shortcoming by implementing HTTP handlers that take as input
arbitrary data, and use it to update the enclave's state.  Consider a system
that takes as input client IP addresses, anonymizes them, and forwards the
anonymized addresses to a back end (cf. \S~\ref{sec:pseudonymization}).  The
service provider now wants to compare submitted IP addresses to a confidental
deny list.  However, if the deny list is hard-coded in the freely available
enclave application, it is readily visible to anyone.

To work around this shortcoming, the service provider can add a new HTTP handler
that takes as input the confidential data it seeks to protect from the users'
eyes.  Once the enclave is running, the service provider can load the
confidential data at runtime, by calling the end point.  To prevent users from
submitting bogus data, the endpoint could hard-code the service provider's
public key and only accept data that carries a valid signature of the service
provider's private key.

The above technique for ingesting secrets into an enclave's runtime is
flexible---so flexible, in fact, that the service provider could abuse it to
ingest code at runtime, which would nullify the verifiability the enclave's
verifiability requirement.  Vigilant users would never trust an enclave whose
code can change at runtime.  We therefore argue that an HTTP handler for the
purpose of injesting secrets must be constrained to a point that only data of a
well-defined type can be injested.

\subsubsection{An Example}

Figure~\ref{fig:hello-world} illustrates an example of a simple ``hello world''
application.  The code initializes a new enclave struct (line 16), followed by
adding a handler that processes requests for \texttt{GET /hello-world} (line
24).  Finally, the application starts the enclave using a function call that
does not return (line 27).

\begin{figure}[t]
\begin{lstlisting}[language=go]
package main

import (
    "fmt"
    "log"
    "net/http"

    nitro "REDACTED"
)

func handler(w http.ResponseWriter, r *http.Request) {
    fmt.Fprintln(w, "hello world")
}

func main() {
    enclave := nitro.NewEnclave(
        &nitro.Config{
            FQDN:    "example.com",
            Port:    8080,
            UseACME: true,
            Debug:   false,
        },
    )
    enclave.AddRoute(http.MethodGet,
                     "/hello-world",
                     handler)
    if err := enclave.Start(); err != nil {
        log.Fatalf("Terminated: %v", err)
    }
}
\end{lstlisting}
\caption{An example of a simple enclave application which registers an HTTP GET
  handler for the path /hello-world (line 24) and, when accessed, responds with
  the string ``hello world'' in the response body (line 12).}
\label{fig:hello-world}
\end{figure}
