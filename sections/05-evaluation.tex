\section{Evaluation}
\label{sec:evaluation}

We evaluate our enclave framework with respect to
security (\S~\ref{sec:security}),
financial cost (\S~\ref{sec:cost}), and performance.  As for performance, we
study the rate at which one can generate
attestation documents (\S~\ref{sec:attestation-performance}),
application latency (\S~\ref{sec:latency}),
and application throughput (\S~\ref{sec:throughput}).

\subsection{Security considerations}
\label{sec:security}

\phw{Need to make this more rigorous.}

There are three key components to the overall security of enclave applications;
(i) Amazon's Nitro enclave system itself,
(ii) our framework, and
(iii) the application that runs on top of our framework.

The very foundation of our framework's security lies in the soundness of the
design of Nitro enclaves.  While Amazon published the conceptual design, the
concrete hardware and software implementation remains confidential.  The
decision to allocate physically separate resources to enclaves appears promising
but only time will tell if Nitro enclaves can resist the types of attacks that
have been plaguing SGX.  If we assume that Nitro enclaves are acceptably
secure, the next critical layer is our software framework.

A significant security aspect of our framework is its size; it is well
understood that complexity is the enemy of security.  Excluding unit tests, our
framework counts less than 1,300 lines of code and has four direct dependencies
that are not maintained by either us or the Go project.\footnote{The
dependencies are chi~\cite{chi} (provides an HTTP request router),
nsm~\cite{nsm} (provides an interface to interact with the Nitro hypervisor),
vsock~\cite{vsock} (provides an API for the VSOCK address family), and
tenus~\cite{tenus} (provides an API to configure Linux's networking devices).}
Four is worse than zero, but is still manageable and reasonably easy to audit in
its entirety.  We believe that our choice of using Go and the deliberately small
trusted computing base greatly reduces---but does not eliminate!---the attack
surface.

The highest layer in the software stack is the enclave application itself.  The
biggest security threat are side channel attacks and programming bugs---both
unintentional and intentional.  It is the application developer's
responsibility to prevent side channel attacks and write bug-free code.  As we
pointed out in Section~\ref{sec:limitations}, programming bugs can be
intentional, i.e., the service provider may deliberately introduce bugs that
leak sensitive information.  From the user's point of view, eternal vigilance
is therefore the price of security.

\subsection{Financial cost}
\label{sec:cost}

Nitro enclaves do not incur any extra cost in addition to what the underlying
EC2 host costs---they can be considered a ``free'' extension to EC2.  Nitro
enclaves are however only available for select types of EC2 instances because
they require their own CPU and a minimum amount of memory, and those instance
types are pricier than the lowest tier that AWS offers.
%
We are currently working on deploying the IP address pseudonymization prototype
that we introduced in Section~\ref{sec:pseudonymization}.  We estimate that our
enclave is going to have to handle an average of 5,000 requests per minute,
coming from more than ten million clients.  Our test deployment uses a single
c5.xlarge EC2 host in the U.S. East region which costs \$0.17 per hour to
operate, amounting to approximately \$125 per month.

\subsection{Attestation documents}
\label{sec:attestation-performance}

The fetching of attestation documents is a critical part of our framework's
overall performance.  We wrote a stress test tool that requests as many
attestation documents as it can over sixty seconds.  The tool is essentially a
minimal enclave application that requests attestation documents in a loop.  For
each attestation document, we asked the hypervisor to include an incrementing
nonce, to avoid any speedups by caching.  We performed our measurements on a
c5.xlarge EC2 host which comes with four CPUs and eight GiB of memory.  We were
able to obtain approximately 900 documents per second, with each request taking
a median of one millisecond ($s = 0.3\,\text{ms}$) to obtain an attestation
document.

\subsection{Application latency}
\label{sec:latency}

Next, we set out to measure the networking latency of the critical path, as
illustrated in Figure~\ref{fig:stress-test}.  In particular, we test the
latency of our TCP proxy, the VSOCK interface between EC2 and enclave, and a
minimal enclave application.
%
We measure latency in three separate setups, designed to help us understand how
much latency each component in our data flow adds:

\begin{figure}[t]
    \centering
    \input{sections/figures/stress-test}
    \caption{Our stress test tool tests the performance of our critical path,
    consisting of the TCP proxy, the VSOCK interface, and \tool{}.}
    \label{fig:stress-test}
\end{figure}

\begin{description}
  \item[Full:] This represents the full data flow as it would occur in
    production, i.e. client $\rightarrow$ TCP proxy $\rightarrow$ VSOCK
    interface $\rightarrow$ enclave application.

  \item[No proxy:] This setup does not contain the TCP proxy, i.e., the client
    talks to the VSOCK interface directly, i.e. client $\rightarrow$ VSOCK
    interface $\rightarrow$ enclave application.

  \item[Direct:] This setup does not contain the TCP proxy and the VSOCK
    interface.  Instead, the client directly talks to an application instance that is
    running \emph{outside} the enclave, i.e., client $\rightarrow$ application.
\end{description}

As part of our measurement setup, We first deploy the code from
Figure~\ref{fig:hello-world}---a minimalistic application that responds with
the string ``hello world'' upon receiving requests for the path /hello-world.
It's important to use a minimalistic application because we're only interested
in the latency that is caused by the components \emph{before} a request reaches
the enclave application.

To simulate clients, we use the HTTP load test tool Baton~\cite{baton}.  We run
Baton on the parent EC2 host and instruct it to send 100,000 requests using 10
concurrent threads.  We had to patch Baton's source code to add VSOCK support
(to be able to send requests directly to the enclave via the VSOCK interface)
and to log latency percentiles.  Note that our measurements constitute a
\emph{lower bound} of the latency that is achievable.  Real-world applications
will exhibit higher latency because clients send their requests over the
Internet (which adds considerable networking latency) and the enclave
application is likely to be more complex (which adds computational latency).

Figure~\ref{fig:latency-msmts} illustrates the results for our three test
setups.  The full pipeline is able to sustain 7,500 requests per second, with a
mean latency of 12.7 milliseconds.  Removing the proxy nearly doubles the
requests to 14,100 per second and lowers the mean latency to 6.5.  Finally, a
direct connection to the application---without proxy and VSOCK interface--once
again nearly doubles the number of requests, reaching 27,900 per second, with a
mean latency of only 3.2 milliseconds.  Figure~\ref{fig:latency-cdf} shows the
empirical CDF of the same latency measurements for our three test setups.

\begin{table}[t]
    \centering
    \begin{tabular}{l r r}
    \toprule
      Setup & C $\rightarrow$ S (Gbits/sec) & S $\rightarrow$ C (Gbit/sec) \\
    \midrule
      Docker          & 26.0 & 28.9 \\
      Enclave         &  3.6 &  3.2 \\
      Nitriding(-nrp) &  0.3 &  1.1 \\
    \bottomrule
    \end{tabular}
    \caption{The TCP throughput measurements when running iperf3 in Docker,
      inside an enclave, or inside an enclave using nitriding.}
    \label{fig:iperf3}
\end{table}

\begin{table}[t]
    \centering
    \begin{tabular}{l r r r}
    \toprule
      Setup & Reqs/sec & \makecell[r]{Mean latency\\(ms)} &
                         \makecell[r]{Max latency\\(ms)} \\
    \midrule
      Docker        & 19,321 &  0.12 & 15 \\
      Enclave       & 16,466 &  0.06 &  9 \\
      Nitriding-nrp &  2,288 &  3.74 & 53 \\
      Nitriding     &  1,214 &  7.63 & 63 \\
    \bottomrule
    \end{tabular}
    \caption{Using 100 concurrent requests and 100,000 requests in total.}
    \label{fig:latency-msmts}
\end{table}

% \begin{figure}[t]
%     \centering
%     \begin{tabular}{l r r r}
%     \toprule
%       Setup & Reqs/sec & Mean lat. (ms) & Max lat. (ms) \\
%     \midrule
%     Full     &  7,500 & 12.7 & 56.0 \\
%     No proxy & 14,100 &  6.5 & 52.0 \\
%     Direct   & 27,900 &  3.2 & 50.0 \\
%     \bottomrule
%     \end{tabular}
%     \caption{Using 100 concurrent requests and 100,000 requests in total.}
%     \label{fig:latency-msmts}
% \end{figure}

\begin{figure}[t]
    \centering
    \input{diagrams/latency-cdf/latency-cdf.tex}
    \label{fig:latency-cdf}
    \caption{The empirical CDF of the latency distributions of our three test
      setups.}
\end{figure}

\subsection{Application throughput}
\label{sec:throughput}

Next, we measure the throughput that we can achieve over the VSOCK interface.
To that end, we use a VSOCK-enabled fork of the iperf3 performance measurement
tool in git commit ~\cite{iperf-vsock}.  iperf3 measures the throughput of a networking link
using a client/server model.  In our experiment, we start an iperf3 server
instance inside the enclave and the corresponding client instance on the parent
EC2 host.\footnote{The command that we ran on the server was
``\texttt{iperf3 -{}-vsock -s}'' and on the client ``\texttt{iperf3 -{}-vsock -c
4}.''} The client then talks to the server via the VSOCK interface and
determines the maximum possible throughput.  In this setup, iperf3 measured a
throughput of 4.09 GBit/s.  For comparison, when running both the iperf3 client
\emph{and} server on the EC2 host---which effectively measures the
throughput of the EC2 host's loopback interface---we achieve 55.5 GBit/s of
throughput.

To develop intuition on the perceived network performance of Nitro enclaves, we
built an enclave application that acts as a SOCKS proxy.  We then configured a
browser to use this enclave-enabled SOCKS proxy and browsed HD videos on
YouTube.  We found that the experience was seamless: videos loaded quickly,
played smoothly, and there was no perceivable latency impact when browsing the
Web.  We believe that the high throughput and low latency, coupled with this
anecdotal user experience report suggests that our framework is suitable for
demanding and latency-sensitive networking applications.

% \subsection{Operational Experience}
% \label{sec:operations}
%
%
% \begin{itemize}
%     \item We deployed application X on YYYY-MM-DD.
%
%     \item How many clients were involved?  How many requests per second did
%     they make?
%
%     \item We published a blog post.  Discuss user reception.
%
%     \item Discuss how useful we found the system in the context of
%     anti-fraud.
%
%     \item Discuss operational issues and gotchas.
% \end{itemize}

\subsection{Synchronization latency}
\label{sec:synclatency}

\phw{Measure how fast enclaves can sync their key material.}
