\section{Evaluation}
\label{sec:evaluation}

Having proposed our enclave construction framework, we now evaluate it with respect to practicality, performance, and security.

\subsection{Performance}
\label{sec:performance}

\begin{itemize}
    \item Throughput. How much data can we shove through the VSOCK interface?
    \item Latency. What's the additional latency (if any) of talking to an application through the VSOCK interface compared to directly?
\end{itemize}

\subsubsection{Attestation Documents}
\label{sec:attestation-performance}

The fetching of attestation documents is a critical part of our framework's overall performance.  We wrote a stress test tool that requests as many attestation documents as it can over sixty seconds.  The tool is essentially a minimal enclave application that does nothing beyond requesting attestation documents.  For each attestation document, we asked the hypervisor to include an incrementing nonce, to avoid any speedups by caching.  We were able to receive approximately 900 documents per second, with each request taking a median of one millisecond ($s = 0.3\,\text{ms}$) to fetch the attestation document.\footnote{We performed our measurements on a c5.xlarge EC2 instance which comes with four CPUs and eight GiB of memory.}

Faster than Intel's attestation service~\cite{Chen2019a}?

\subsubsection{End-to-end Performance}
\label{sec:end-to-end}

Next, we set out to measure the networking throughput of the critical path, as illustrated in Figure~\ref{fig:stress-test}.  In particular, we test latency and throughput of our TCP proxy, the VSOCK interface between EC2 and enclave, and a minimal enclave application.  To rule out unnecessary computation in the enclave application, we implemented a simple service whose only job it is to respond with the string ``hello world'' when clients request the path /hello-world.  To simulate clients, we use the HTTP load test tool Baton~\cite{baton}, which sends concurrent HTTP requests to the application.  We run Baton on the parent EC2 instance and make it send requests to the TCP proxy.  Note that this test setup constitutes a \emph{lower bound} of the performance that is achievable.  Real-world applications will be slower because clients send their request over the Internet (which adds latency) and the enclave application is likely to be more complex (which adds latency).

\begin{figure}[t]
    \centering
    \input{sections/figures/stress-test}
    \label{fig:stress-test}
    \caption{Our stress test tool tests the performance of our critical path, consisting of the TCP proxy, the VSOCK interface, and Go's HTTP stack in the enclave application.}
\end{figure}

\begin{figure}[t]
    \centering
    \begin{tabular}{l r r r}
    \toprule
    Setup & Reqs/sec & Mean lat. & Max lat. \\
    \midrule
    Full & ~7,500 & 12.7 & 56.0 \\
    No proxy & 14,100 & 6.5 & 52.0 \\
    Direct & ~27,900 & 3.2 & 50.0 \\
    \bottomrule
    \end{tabular}
    \caption{Using 100 concurrent requests and 100,000 requests in total.}
    \label{tab:my_label}
\end{figure}


\begin{figure}[t]
    \centering
    \input{sections/figures/latency-cdf}
    \label{fig:latency-cdf}
    \caption{The empirical CDF of the latency distributions of our three test setups.}
\end{figure}

\subsection{Operational Experience}
\label{sec:operations}

\begin{itemize}
    \item We deployed application X on YYYY-MM-DD.
    \item How many clients were involved?  How many requests per second did they make?
    \item We published a blog post.  Discuss user reception.
    \item Discuss how useful we found the system in the context of anti-fraud.
    \item Discuss operational issues and gotchas.
\end{itemize}
